{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for calculating sentiment, readability and length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gzip\n",
    "import csv\n",
    "import string\n",
    "import math\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import cmudict\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from datetime import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Hqs4YNST_ZHbshwyi4bnsQ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The customer service of the owner made me give...</td>\n",
       "      <td>1.539293e+09</td>\n",
       "      <td>Restaurants, Pizza, American (Traditional), It...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Hqs4YNST_ZHbshwyi4bnsQ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>I used to drive from summerlin to go here beca...</td>\n",
       "      <td>1.538919e+09</td>\n",
       "      <td>Restaurants, Pizza, American (Traditional), It...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>bPcqucuuClxYrIM8xWoArg</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Did anyone mention bacon chocolate ice cream. ...</td>\n",
       "      <td>1.317320e+09</td>\n",
       "      <td>Nightlife, Bars, Italian, Pizza, Wine Bars, Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>hubbaEcYPYEZu5Ziz6i0lw</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I like the Lamb Tandoori dish they do a lot. I...</td>\n",
       "      <td>1.304258e+09</td>\n",
       "      <td>Restaurants, Pakistani, Indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5aeR9KcboZmhDZlFscnYRA</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>So Fresh Mama let us host a Homeschool Board G...</td>\n",
       "      <td>1.358296e+09</td>\n",
       "      <td>Food, Restaurants, Internet Cafes, Juice Bars ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender             business_id  stars  useful  \\\n",
       "0     1.0  Hqs4YNST_ZHbshwyi4bnsQ    5.0     0.0   \n",
       "1     1.0  Hqs4YNST_ZHbshwyi4bnsQ    1.0     0.0   \n",
       "2     1.0  bPcqucuuClxYrIM8xWoArg    5.0     4.0   \n",
       "3     1.0  hubbaEcYPYEZu5Ziz6i0lw    4.0     1.0   \n",
       "4     1.0  5aeR9KcboZmhDZlFscnYRA    5.0     1.0   \n",
       "\n",
       "                                                text     timestamp  \\\n",
       "0  The customer service of the owner made me give...  1.539293e+09   \n",
       "1  I used to drive from summerlin to go here beca...  1.538919e+09   \n",
       "2  Did anyone mention bacon chocolate ice cream. ...  1.317320e+09   \n",
       "3  I like the Lamb Tandoori dish they do a lot. I...  1.304258e+09   \n",
       "4  So Fresh Mama let us host a Homeschool Board G...  1.358296e+09   \n",
       "\n",
       "                                          categories  \n",
       "0  Restaurants, Pizza, American (Traditional), It...  \n",
       "1  Restaurants, Pizza, American (Traditional), It...  \n",
       "2  Nightlife, Bars, Italian, Pizza, Wine Bars, Re...  \n",
       "3                     Restaurants, Pakistani, Indian  \n",
       "4  Food, Restaurants, Internet Cafes, Juice Bars ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read csv\n",
    "disclosed_flag = False\n",
    "if disclosed_flag:\n",
    "    fields = ['business_id','gender','useful','text', 'stars', 'timestamp', 'categories']\n",
    "    raw_df = pd.read_csv('disclosed_dataset.csv', usecols=fields)\n",
    "    mapping = {'female' : 1, 'male' : 0}\n",
    "    raw_df.replace({'gender': mapping}, inplace=True)\n",
    "else:\n",
    "    fields = ['business_id','predicted_gender','useful','text', 'stars', 'timestamp', 'categories']\n",
    "    raw_df = pd.read_csv('undisclosed_predicted_dataset.csv', usecols=fields)\n",
    "    raw_df.rename(columns={'predicted_gender': 'gender'}, inplace=True)\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undisclosed 0 or 1 csv not exist\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "\n",
    "df_dict = {}\n",
    "if disclosed_flag:\n",
    "    if not os.path.exists('disclosed_0.csv') or not os.path.exists('disclosed_1.csv'):\n",
    "        for i, g in raw_df.groupby('gender'):\n",
    "            df_dict[i] = g\n",
    "            g.to_csv('disclosed_{}.csv'.format(i), index=False)\n",
    "    else:\n",
    "        df_male = pd.read_csv('disclosed_0.csv')\n",
    "        df_female = pd.read_csv('disclosed_1.csv')\n",
    "else:\n",
    "    if not os.path.exists('undisclosed_0.csv') or not os.path.exists('undisclosed_1.csv'):\n",
    "        print('undisclosed 0 or 1 csv not exist')\n",
    "        for i, g in raw_df.groupby('gender'):\n",
    "            df_dict[i] = g\n",
    "            g.to_csv('undisclosed_{}.csv'.format(i), index=False)\n",
    "    else:\n",
    "        df_male = pd.read_csv('undisclosed_0.csv')\n",
    "        df_female = pd.read_csv('undisclosed_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>JJxI7OA8wgr8ZMuwaKborQ</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Tough to find places around here to eat, so my...</td>\n",
       "      <td>1.375885e+09</td>\n",
       "      <td>Peruvian, Restaurants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>IB8zLlGraOg9LU7qQVLPyg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>Nach unserem entt√§uschenden Besuch im Outlet C...</td>\n",
       "      <td>1.443752e+09</td>\n",
       "      <td>Restaurants, Fast Food, Shopping Centers, Shop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9edPSkfXKsJmkZYIaOmA7Q</td>\n",
       "      <td>4.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>Nachdem wir die Las Vegas North Premium Outlet...</td>\n",
       "      <td>1.509952e+09</td>\n",
       "      <td>Outlet Stores, Restaurants, Shopping Centers, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>GHS1rVjO-RMcRB6WJLpCDQ</td>\n",
       "      <td>3.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>In Las Vegas kann man zwischen zwei verschiede...</td>\n",
       "      <td>1.442370e+09</td>\n",
       "      <td>Outlet Stores, Shopping Centers, Restaurants, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SMPbvZLSMMb7KU76YNYMGg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>Nach einem Spaziergang durch das exklusive Cry...</td>\n",
       "      <td>1.515274e+09</td>\n",
       "      <td>Hotels &amp; Travel, Arts &amp; Entertainment, Hotels,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     gender             business_id  stars  useful  \\\n",
       "130     0.0  JJxI7OA8wgr8ZMuwaKborQ    4.0     0.0   \n",
       "134     0.0  IB8zLlGraOg9LU7qQVLPyg    4.0   129.0   \n",
       "135     0.0  9edPSkfXKsJmkZYIaOmA7Q    4.0   204.0   \n",
       "136     0.0  GHS1rVjO-RMcRB6WJLpCDQ    3.0   113.0   \n",
       "137     0.0  SMPbvZLSMMb7KU76YNYMGg    4.0   201.0   \n",
       "\n",
       "                                                  text     timestamp  \\\n",
       "130  Tough to find places around here to eat, so my...  1.375885e+09   \n",
       "134  Nach unserem entt√§uschenden Besuch im Outlet C...  1.443752e+09   \n",
       "135  Nachdem wir die Las Vegas North Premium Outlet...  1.509952e+09   \n",
       "136  In Las Vegas kann man zwischen zwei verschiede...  1.442370e+09   \n",
       "137  Nach einem Spaziergang durch das exklusive Cry...  1.515274e+09   \n",
       "\n",
       "                                            categories  \n",
       "130                              Peruvian, Restaurants  \n",
       "134  Restaurants, Fast Food, Shopping Centers, Shop...  \n",
       "135  Outlet Stores, Restaurants, Shopping Centers, ...  \n",
       "136  Outlet Stores, Shopping Centers, Restaurants, ...  \n",
       "137  Hotels & Travel, Arts & Entertainment, Hotels,...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_male = df_dict[0]\n",
    "df_female = df_dict[1]\n",
    "df_male.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_punctuation = lambda w: not (len(w)==1 and (not w.isalpha()))\n",
    "get_sent_count = lambda text: len(sent_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENIZER = RegexpTokenizer('(?u)\\W+|\\$[\\d\\.]+|\\S+')\n",
    "SPECIAL_CHARS = ['.', ',', '!', '?']\n",
    "\n",
    "def get_words(text=''):\n",
    "    words = []\n",
    "    words = TOKENIZER.tokenize(text)\n",
    "    filtered_words = []\n",
    "    for word in words:\n",
    "        if word in SPECIAL_CHARS or word == \" \":\n",
    "            pass\n",
    "        else:\n",
    "            new_word = word.replace(\",\",\"\").replace(\".\",\"\")\n",
    "            new_word = new_word.replace(\"!\",\"\").replace(\"?\",\"\")\n",
    "            filtered_words.append(new_word)\n",
    "    return filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('cmudict')\n",
    "prondict = cmudict.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numsyllables(word):\n",
    "    try:\n",
    "        return [len(list(y for y in x if (y[-1]).isdigit())) for x in prondict[word.lower()]]\n",
    "    except KeyError:\n",
    "        return [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_statistics(text):\n",
    "    word_count = len(get_words(text))\n",
    "    sent_count = get_sent_count(text)\n",
    "    #if more than one pronunciation, take the largest no. of syllables\n",
    "    syllable_count = sum(map(lambda w: max(numsyllables(w)), word_tokenize(text)))\n",
    "    \n",
    "    analyzedVars = {\n",
    "        'word_cnt': float(word_count),\n",
    "        'sentence_cnt': float(sent_count),\n",
    "        'syllable_cnt': float(syllable_count),\n",
    "    }\n",
    "    \n",
    "    return analyzedVars['word_cnt'],analyzedVars['sentence_cnt'], analyzedVars['syllable_cnt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flesch Kincaid measure of readability\n",
    "\n",
    "#readability ease\n",
    "flesch_formula = lambda word_count, sent_count, syllable_count: 206.835 - 1.015*word_count/sent_count - 84.6*syllable_count/word_count\n",
    "\n",
    "def flesch(text):\n",
    "    word_count, sent_count, syllable_count = text_statistics(text)\n",
    "    #print(word_count,sent_count,syllable_count)\n",
    "    score = 0.0\n",
    "    if word_count > 0.0:\n",
    "        score = round(flesch_formula(word_count, sent_count, syllable_count))\n",
    "    return score\n",
    "\n",
    "#grade level\n",
    "fk_formula = lambda word_count, sent_count, syllable_count : 0.39 * word_count / sent_count + 11.8 * syllable_count / word_count - 15.59\n",
    "\n",
    "def flesch_kincaid(text):\n",
    "    word_count, sent_count, syllable_count = text_statistics(text)\n",
    "    score = 0.0\n",
    "    if word_count > 0.0:\n",
    "        score = round(fk_formula(word_count, sent_count, syllable_count))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def length(text):\n",
    "    word_count, sent_count, syllable_count = text_statistics(text)\n",
    "    return word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')\n",
    "# nltk 'punkt'\n",
    "words = stopwords.words(\"english\")\n",
    "\n",
    "#remove punctuation for each word\n",
    "#maketrans() method returns a translation table that maps each character in the \n",
    "#intab string into the character at the same position in the outtab string\n",
    "table = str.maketrans('', '', string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "\n",
    "# nltk.download('vader_lexicon')\n",
    "sia = SIA()\n",
    "\n",
    "def sentiment(text):\n",
    "    cleaned_text = \" \".join([i.translate(table) for i in text.split() if i.isalpha() if i not in words]).lower()\n",
    "    return sia.polarity_scores(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_male = df_male.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_male['Sentiment'] = df_male['text'].apply(lambda x: sentiment(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_male['Grade_level'] = df_male['text'].apply(lambda x: flesch_kincaid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_male['length'] = df_male['text'].apply(lambda x: length(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if disclosed_flag:\n",
    "    df_male.to_csv('disclosed_male_l_s_r.csv', sep='|')\n",
    "else:\n",
    "    df_male.to_csv('undisclosed_male_l_s_r.csv',sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>categories</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Grade_level</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>JJxI7OA8wgr8ZMuwaKborQ</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Tough to find places around here to eat, so my...</td>\n",
       "      <td>1.375885e+09</td>\n",
       "      <td>Peruvian, Restaurants</td>\n",
       "      <td>{'neg': 0.094, 'neu': 0.729, 'pos': 0.176, 'co...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>IB8zLlGraOg9LU7qQVLPyg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>Nach unserem entt√§uschenden Besuch im Outlet C...</td>\n",
       "      <td>1.443752e+09</td>\n",
       "      <td>Restaurants, Fast Food, Shopping Centers, Shop...</td>\n",
       "      <td>{'neg': 0.132, 'neu': 0.868, 'pos': 0.0, 'comp...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>230.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9edPSkfXKsJmkZYIaOmA7Q</td>\n",
       "      <td>4.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>Nachdem wir die Las Vegas North Premium Outlet...</td>\n",
       "      <td>1.509952e+09</td>\n",
       "      <td>Outlet Stores, Restaurants, Shopping Centers, ...</td>\n",
       "      <td>{'neg': 0.094, 'neu': 0.906, 'pos': 0.0, 'comp...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>203.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>GHS1rVjO-RMcRB6WJLpCDQ</td>\n",
       "      <td>3.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>In Las Vegas kann man zwischen zwei verschiede...</td>\n",
       "      <td>1.442370e+09</td>\n",
       "      <td>Outlet Stores, Shopping Centers, Restaurants, ...</td>\n",
       "      <td>{'neg': 0.169, 'neu': 0.822, 'pos': 0.01, 'com...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>266.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SMPbvZLSMMb7KU76YNYMGg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>Nach einem Spaziergang durch das exklusive Cry...</td>\n",
       "      <td>1.515274e+09</td>\n",
       "      <td>Hotels &amp; Travel, Arts &amp; Entertainment, Hotels,...</td>\n",
       "      <td>{'neg': 0.056, 'neu': 0.944, 'pos': 0.0, 'comp...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>249.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     gender             business_id  stars  useful  \\\n",
       "130     0.0  JJxI7OA8wgr8ZMuwaKborQ    4.0     0.0   \n",
       "134     0.0  IB8zLlGraOg9LU7qQVLPyg    4.0   129.0   \n",
       "135     0.0  9edPSkfXKsJmkZYIaOmA7Q    4.0   204.0   \n",
       "136     0.0  GHS1rVjO-RMcRB6WJLpCDQ    3.0   113.0   \n",
       "137     0.0  SMPbvZLSMMb7KU76YNYMGg    4.0   201.0   \n",
       "\n",
       "                                                  text     timestamp  \\\n",
       "130  Tough to find places around here to eat, so my...  1.375885e+09   \n",
       "134  Nach unserem entt√§uschenden Besuch im Outlet C...  1.443752e+09   \n",
       "135  Nachdem wir die Las Vegas North Premium Outlet...  1.509952e+09   \n",
       "136  In Las Vegas kann man zwischen zwei verschiede...  1.442370e+09   \n",
       "137  Nach einem Spaziergang durch das exklusive Cry...  1.515274e+09   \n",
       "\n",
       "                                            categories  \\\n",
       "130                              Peruvian, Restaurants   \n",
       "134  Restaurants, Fast Food, Shopping Centers, Shop...   \n",
       "135  Outlet Stores, Restaurants, Shopping Centers, ...   \n",
       "136  Outlet Stores, Shopping Centers, Restaurants, ...   \n",
       "137  Hotels & Travel, Arts & Entertainment, Hotels,...   \n",
       "\n",
       "                                             Sentiment  Grade_level  length  \n",
       "130  {'neg': 0.094, 'neu': 0.729, 'pos': 0.176, 'co...          9.0    53.0  \n",
       "134  {'neg': 0.132, 'neu': 0.868, 'pos': 0.0, 'comp...         -1.0   230.0  \n",
       "135  {'neg': 0.094, 'neu': 0.906, 'pos': 0.0, 'comp...         -1.0   203.0  \n",
       "136  {'neg': 0.169, 'neu': 0.822, 'pos': 0.01, 'com...          1.0   266.0  \n",
       "137  {'neg': 0.056, 'neu': 0.944, 'pos': 0.0, 'comp...          0.0   249.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_male.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del df_male\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_female = df_female.dropna()\n",
    "df_female['Grade_level'] = df_female['text'].apply(lambda x: flesch_kincaid(x))\n",
    "df_female['length'] = df_female['text'].apply(lambda x: length(x))\n",
    "df_female['Sentiment'] = df_female['text'].apply(lambda x: sentiment(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if disclosed_flag:\n",
    "    df_female.to_csv('disclosed_female_l_s_r.csv', sep='|')\n",
    "else:\n",
    "    df_female.to_csv('undisclosed_female_l_s_r.csv', sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
