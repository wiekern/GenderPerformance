{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find matches in each pair group (DM, DF), (DM, UM), (DF, UF), (UM, UF), hen analyzing matched of each pair group to get a conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm\n",
    "import pickle\n",
    "import random\n",
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import distance\n",
    "from scipy import linalg\n",
    "from sklearn.utils import resample\n",
    "from scipy import stats\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "current_dir = Path.cwd()\n",
    "csv_files_dir = 'csv_files'\n",
    "root_dir = current_dir / Path(csv_files_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dis_male = pd.read_csv('disclosed_male.csv',sep='|')\n",
    "# Load disclosed male\n",
    "dis_male = pd.read_csv(root_dir / Path('disclosed_male_l_s_r.csv'), sep='|', index_col=0)\n",
    "dis_male = dis_male.reset_index(drop=True)\n",
    "dis_male['Sentiment'] = dis_male.Sentiment.apply(lambda x: ast.literal_eval(x)['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dis_female = pd.read_csv('disclosed_female.csv',sep='|')\n",
    "# Load disclosed female\n",
    "dis_female = pd.read_csv(root_dir / Path('disclosed_female_l_s_r.csv'), sep='|', index_col=0)\n",
    "dis_female = dis_female.reset_index(drop=True)\n",
    "dis_female['Sentiment'] = dis_female.Sentiment.apply(lambda x: ast.literal_eval(x)['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# undis_male = pd.read_csv('undisclosed_male.csv',sep='|')\n",
    "# Load undisclosed male\n",
    "undis_male = pd.read_csv(root_dir / ('undisclosed_male_l_s_r.csv'),sep='|', index_col=0)\n",
    "undis_male = undis_male.reset_index(drop=True)\n",
    "undis_male['Sentiment'] = undis_male.Sentiment.apply(lambda x: ast.literal_eval(x)['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# undis_female = pd.read_csv('undisclosed_female.csv',sep='|')\n",
    "# Load undisclosed female\n",
    "undis_female = pd.read_csv(root_dir / Path('undisclosed_female_l_s_r.csv'), sep='|', index_col=0)\n",
    "undis_female = undis_female.reset_index(drop=True)\n",
    "undis_female['Sentiment'] = undis_female.Sentiment.apply(lambda x: ast.literal_eval(x)['compound'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Legecy code, just for your information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat = undis_male.iloc[0]['categories'].replace('[','').replace(']','').replace('\\'','').split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCategoryList(x):\n",
    "    return reduce(lambda a,b: a+b, ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "undis_male = undis_male.drop(columns=['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "undis_male.iloc[0]['categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "undis_female = undis_female.rename(columns={'categories':'category'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "undis_female.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "undis_female['categories'] = undis_female['category'].apply(lambda x:getCategoryList(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "undis_female.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "undis_female = undis_female.drop(columns=['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "undis_male = undis_male.rename(columns={'categories':'category'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "undis_male['categories'] = undis_male['category'].apply(lambda x:getCategoryList(x))\n",
    "undis_male = undis_male.drop(columns=['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "undis_female.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "undis_male.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_female = dis_female.rename(columns={'categories':'category'})\n",
    "dis_female['categories'] = dis_female['category'].apply(lambda x:getCategoryList(x))\n",
    "dis_female = dis_female.drop(columns=['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_male = dis_male.rename(columns={'categories':'category'})\n",
    "dis_male['categories'] = dis_male['category'].apply(lambda x:getCategoryList(x))\n",
    "dis_male = dis_male.drop(columns=['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterCategory(x,category):\n",
    "    if category in x.lower():\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mahalanobis Distance\n",
    "def calculateCdist(df_1_s, df_2, cov_inv):\n",
    "    cnt = df_2.shape[0]\n",
    "    slice_len = 250000\n",
    "    obtained_pairs = []\n",
    "    similarity_val = []\n",
    "    n = df_1_s.shape[0]\n",
    "    if cnt > slice_len:\n",
    "        slice_cnt = int(cnt/slice_len)+1\n",
    "        for i in range(slice_cnt):\n",
    "            u_s = i * slice_len\n",
    "            \n",
    "            if i < slice_cnt-1:\n",
    "                u_e = u_s + slice_len\n",
    "                df_2_s = df_2[u_s:u_e]\n",
    "            else:\n",
    "                df_2_s = df_2[u_s:]\n",
    "\n",
    "            Y = distance.cdist(df_1_s[['stars', 'timestamp', 'length', 'Grade_level', 'Sentiment']], \\\n",
    "                               df_2_s[['stars', 'timestamp', 'length', 'Grade_level', 'Sentiment']], \\\n",
    "                               'mahalanobis', VI=cov_inv)\n",
    "            Y_1 = Y.argmin(axis=1)\n",
    "\n",
    "\n",
    "            min_y = [(Y_1[j], Y[j, Y_1[j]], i) for j in range(n)]\n",
    "            obtained_pairs.append(min_y)\n",
    "\n",
    "        # obtaining the matched set\n",
    "        matched_set = []\n",
    "        for i in range(n):\n",
    "            for ind,val,s in sorted(list(zip(*obtained_pairs))[i], key=lambda x:x[1]):\n",
    "                pos = s * slice_len + ind\n",
    "                matched_set.append(pos)\n",
    "                similarity_val.append(val)\n",
    "                break\n",
    "        \n",
    "        return matched_set,similarity_val\n",
    "    \n",
    "    else:\n",
    "        Y = distance.cdist(df_1_s[['stars', 'timestamp', 'length', 'Grade_level', 'Sentiment']], \\\n",
    "                           df_2[['stars', 'timestamp', 'length', 'Grade_level', 'Sentiment']], \\\n",
    "                           'mahalanobis', VI=cov_inv)\n",
    "        Y_1 = Y.argmin(axis=1)\n",
    "        \n",
    "        for i in range(Y.shape[0]):\n",
    "            similarity_val.append(Y[i,Y_1[i]])\n",
    "        \n",
    "        return Y_1, similarity_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISCLOSED_MALE = 0\n",
    "DISCLOSED_FEMALE = 1\n",
    "UNDISCLOSED_MALE = 2\n",
    "UNDISCLOSED_FEMALE = 3\n",
    "def findMatchAllPairs(d_m, d_f, u_m, u_f, sample_size=None):\n",
    "    total_size =  d_m.shape[0] + d_f.shape[0] + u_m.shape[0] + u_f.shape[0]\n",
    "    if sample_size is None:\n",
    "        sample_size = total_size\n",
    "    elif sample_size > total_size:\n",
    "        raise Exception('sample size beyond the number of population.')\n",
    "        \n",
    "    print(sample_size)\n",
    "    pairs = {}\n",
    "    \n",
    "    if 'group' not in d_m.columns:\n",
    "        d_m.insert(0,'group', DISCLOSED_MALE)\n",
    "    if 'group' not in d_f.columns:\n",
    "        d_f.insert(0,'group', DISCLOSED_FEMALE)\n",
    "    if 'group' not in u_m.columns:\n",
    "        u_m.insert(0,'group', UNDISCLOSED_MALE)\n",
    "    if 'group' not in u_f.columns:\n",
    "        u_f.insert(0,'group', UNDISCLOSED_FEMALE)\n",
    "    \n",
    "    all_data = pd.concat([d_m, d_f, u_m, u_f])\n",
    "    \n",
    "    if sample_size is None:\n",
    "        saple_n = all_data\n",
    "    else:\n",
    "        sample_n = all_data.sample(sample_size)\n",
    "    \n",
    "    samp_0 = sample_n[sample_n['group'] == DISCLOSED_MALE]\n",
    "    samp_1 = sample_n[sample_n['group'] == DISCLOSED_FEMALE]\n",
    "    samp_2 = sample_n[sample_n['group'] == UNDISCLOSED_MALE]\n",
    "    samp_3 = sample_n[sample_n['group'] == UNDISCLOSED_FEMALE]\n",
    "    \n",
    "    print(f'sample DM - {len(samp_0)}, sample DF - {len(samp_1)}, \\\n",
    "    sample UM - {len(samp_2)}, sample UF - {len(samp_3)}')\n",
    "    \n",
    "    data = [(samp_0, DISCLOSED_MALE), (samp_1, DISCLOSED_FEMALE), (samp_2, UNDISCLOSED_MALE), (samp_3, UNDISCLOSED_FEMALE)]\n",
    "    \n",
    "    for i in range(3):\n",
    "        samp_treatment, label_treatment = data[i]\n",
    "        popln_treatment = all_data[all_data['group'] == label_treatment]\n",
    "        \n",
    "        for j in range(i+1, 4):\n",
    "            samp_control, label_control = data[j] \n",
    "            popln_control = all_data[all_data['group'] == label_control]\n",
    "\n",
    "            pop_size = popln_treatment.shape[0] + popln_control.shape[0]\n",
    "            \n",
    "            if pop_size < 1000000:\n",
    "                m = pop_size\n",
    "            else:\n",
    "                m = 1000000\n",
    "\n",
    "            all_sample = pd.concat([popln_treatment, popln_control])\n",
    "        \n",
    "            cov = np.cov(all_sample[['stars','timestamp','length','Grade_level','Sentiment']].sample(m).values, rowvar=False)\n",
    "            cov_inv = linalg.inv(cov)\n",
    "\n",
    "            print('covariance matrix obtained')\n",
    "            \n",
    "            Y_1, similarity_1 = calculateCdist(samp_treatment, popln_control, cov_inv) \n",
    "            pair_0_0 = [samp_treatment.iloc[i] for i in range(samp_treatment.shape[0])]\n",
    "            pair_1_0 = [popln_control.iloc[i] for i in Y_1]\n",
    "            pairs[str(label_treatment) + '-' + str(label_control)] = list(zip(pair_0_0, pair_1_0)) \n",
    "            \n",
    "            Y_1,similarity_2 = calculateCdist(samp_control, popln_treatment, cov_inv)\n",
    "            pair_0_1 = [popln_treatment.iloc[i] for i in Y_1]\n",
    "            pair_1_1 = [samp_control.iloc[i] for i in range(samp_control.shape[0])]\n",
    "            pairs[str(label_control) + '-' + str(label_treatment)] = list(zip(pair_0_1, pair_1_1))\n",
    "                   \n",
    "    return pairs  #,similarity_1,similarity_2                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of a specific category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = 'restaurants'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterCategory(x,category):\n",
    "    if category in x.lower():\n",
    "        return True\n",
    "    return False\n",
    "dis_male_c = dis_male[dis_male['categories'].apply(lambda x:filterCategory(x,category))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_male_c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_female_c = dis_female[dis_female['categories'].apply(lambda x:filterCategory(x,category))]\n",
    "undis_male_c = undis_male[undis_male['categories'].apply(lambda x:filterCategory(x,category))]\n",
    "undis_female_c = undis_female[undis_female['categories'].apply(lambda x:filterCategory(x,category))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_female_c.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_all = findMatchAllPairs(dis_male_c,dis_female_c,undis_male_c,undis_female_c, 40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = pairs_all\n",
    "pairs.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterating over all categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterCategory(x,category):\n",
    "    if category in x.lower():\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "correlated_restaurants = False\n",
    "if correlated_restaurants:\n",
    "    with open('correlated_categories.json') as json_file:\n",
    "        categories = json.load(json_file)\n",
    "else:\n",
    "    with open('top_n_correlated_categories.json') as json_file:\n",
    "        categories = json.load(json_file)\n",
    "    categories = list(categories.keys())\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "if 'group' not in dis_male.columns:\n",
    "    dis_male.insert(0, 'group', DISCLOSED_MALE)\n",
    "if 'group' not in dis_female.columns:\n",
    "    dis_female.insert(0, 'group', DISCLOSED_FEMALE)\n",
    "if 'group' not in undis_male.columns:\n",
    "    undis_male.insert(0, 'group', UNDISCLOSED_MALE)\n",
    "if 'group' not in undis_female.columns:\n",
    "    undis_female.insert(0, 'group', UNDISCLOSED_FEMALE)\n",
    "\n",
    "# run n times \n",
    "sample_times = 1\n",
    "for i in range(0, sample_times): # one sample enough\n",
    "    for category in categories:\n",
    "        print(f'category - {category}')\n",
    "        \n",
    "        d_m_c = dis_male[dis_male['categories'].apply(lambda x:filterCategory(x, category))]\n",
    "        d_f_c = dis_female[dis_female['categories'].apply(lambda x:filterCategory(x, category))]\n",
    "        u_m_c = undis_male[undis_male['categories'].apply(lambda x:filterCategory(x, category))]\n",
    "        u_f_c = undis_female[undis_female['categories'].apply(lambda x:filterCategory(x, category))]\n",
    "\n",
    "        pairs = findMatchAllPairs(d_m_c, d_f_c, u_m_c, u_f_c, 10000)\n",
    "    \n",
    "        path = Path('category_pairs/sample_' + str(i))\n",
    "        abs_file = path / Path(category + '.pickle')\n",
    "        if not path.exists():                                    \n",
    "            path.mkdir(parents=True)\n",
    "        with open(abs_file, 'wb+') as ft:\n",
    "            pickle.dump(pairs, ft)\n",
    "    \n",
    "    print(f'finished sample - {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perIncr(x,y):\n",
    "    return (x-y)/min([x,y])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateMean(h):\n",
    "    return np.mean([x[0] for x in h]),np.mean([x[1] for x in h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHelfulnessScore(pairs,keys):\n",
    "    h1 = [(m_1.useful, m_2.useful) for m_1, m_2 in pairs[keys[0]]]\n",
    "    h2 = [(m_1.useful, m_2.useful) for m_1, m_2 in pairs[keys[1]]]\n",
    "    return h1, h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateMetric(pairs, key=None, bootstrap=False):\n",
    "    res = {}\n",
    "\n",
    "    for i in range(3):\n",
    "        for j in range(i + 1, 4):\n",
    "            key_1 = str(i) + '-' + str(j)\n",
    "            key_2 = str(j) + '-' + str(i)\n",
    "            \n",
    "            h1, h2 = getHelfulnessScore(pairs, (key_1, key_2))\n",
    "            #total = h1 + h2\n",
    "            est = []\n",
    "            if bootstrap:\n",
    "                for _ in range(1000):\n",
    "                    total_set = h1 + h2 \n",
    "                    bootstrap_set = resample(total_set)\n",
    "                    h_s_1, h_s_2 = calculateMean(bootstrap_set)\n",
    "                    est.append(perIncr(h_s_1, h_s_2))\n",
    "                \n",
    "                res[key_1] = (np.mean(est), stats.sem(est), np.std(est))\n",
    "            else:\n",
    "                h_s_1, h_s_2 = calculateMean(h1 + h2)\n",
    "                res[key_1] = perIncr(h_s_1, h_s_2)\n",
    "                \n",
    "    return res, est#,total   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [optional] connect to the part Example of a specific category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res, est = calculateMetric(pairs, bootstrap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est, np.mean(est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pairs['2-3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs['3-2'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total[3666]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('category_pairs/sample_1/Books.pickle','rb') as fs:\n",
    "    pairs = pickle.load(fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculateMetric(pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# connect to the part iterating over all categories\n",
    "# [deprecated] sampling without bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# categories = ['Books','Electronics','CDs & Vinyl','Clothing, Shoes & Jewelry','Home & Kitchen',\\\n",
    "#              'Kindle Store','Sports & Outdoors','Cell Phones & Accessories', 'Toys & Games','Games','Literature & Fiction',\\\n",
    "#              'Beauty','Health & Personal Care','Movies','Computers']\n",
    "\n",
    "all_results = {}\n",
    "for category in tqdm.tqdm(categories):\n",
    "\n",
    "    results = {'0-1':[], '0-2':[], '0-3':[], '1-2':[], '1-3':[], '2-3':[]}\n",
    "    \n",
    "    for _ in range(0, 1):\n",
    "        path = 'category_pairs/sample_' + str(_) + '/' + category + '.pickle'\n",
    "        with open(path, 'rb') as fs:\n",
    "            pairs = pickle.load(fs)\n",
    "        res, _ = calculateMetric(pairs, boostrap=)\n",
    "        for key in res:\n",
    "            results[key].append(res[key])\n",
    "    \n",
    "    mean_res = {}\n",
    "    for key in results.keys():\n",
    "        mean_res[key] = (np.mean(results[key]), np.std(results[key])) # scipy.stats.sem(results[key])\n",
    "    \n",
    "    all_results[category] = mean_res\n",
    "    \n",
    "    print(f'done for {category}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories = ['Books','Electronics','CDs & Vinyl','Clothing, Shoes & Jewelry','Home & Kitchen',\\\n",
    "#              'Kindle Store','Sports & Outdoors','Cell Phones & Accessories', 'Toys & Games','Games','Literature & Fiction',\\\n",
    "#              'Beauty','Health & Personal Care','Movies','Computers']\n",
    "\n",
    "all_results = {}\n",
    "for category in tqdm.tqdm(categories):\n",
    "\n",
    "    results = {'0-1':[], '0-2':[], '0-3':[], '1-2':[], '1-3':[], '2-3':[]}\n",
    "    \n",
    "    for _ in range(13, 15):\n",
    "        path = 'category_pairs/sample_' + str(_) + '/' + category + '.pickle'\n",
    "        with open(path, 'rb') as fs:\n",
    "            pairs = pickle.load(fs)\n",
    "        res, _ = calculateMetric(pairs)\n",
    "        for key in res:\n",
    "            results[key].append(res[key])\n",
    "    \n",
    "    mean_res = {}\n",
    "    for key in results.keys():\n",
    "        mean_res[key] = (np.mean(results[key]),  scipy.stats.sem((results[key]))\n",
    "    \n",
    "    all_results[category] = mean_res\n",
    "    \n",
    "    print(f'done for {category}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = '0-2'\n",
    "mean_results = []\n",
    "for category in categories:\n",
    "    print(category, all_results[category][key])\n",
    "    mean_results.append(all_results[category][key][0])\n",
    "mean = sum(mean_results) / len(mean_results)    \n",
    "mean_results.append(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories\n",
    "cat_plot = ('sewing & alterations', 'self storage', 'carpet cleaning', \n",
    "            'oral surgeons', \"men's hair salons\", 'restaurants', 'overall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "from matplotlib.ticker import MultipleLocator, FormatStrFormatter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "#mpl.style.use('classic')\n",
    "mpl.rcParams['xtick.labelsize'] = 25\n",
    "mpl.rcParams['ytick.labelsize'] = 32\n",
    "mpl.rcParams['font.size'] = 20\n",
    "mpl.rcParams['figure.figsize'] =  9, 10\n",
    "mpl.rcParams['axes.labelsize'] = 35\n",
    "mpl.rcParams['mathtext.fontset'] = 'stix'\n",
    "mpl.rcParams['font.family'] = 'STIXGeneral'\n",
    "mpl.rcParams['axes.linewidth'] = 2.5\n",
    "#plotResults(per_incr,std_err,'UF','UM')\n",
    "\n",
    "ind = np.arange(5)    \n",
    "width = 0.35 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotResults(per_incr, grp_1, grp_2, std_err=None, dir_=''):\n",
    "    #plt.rcdefaults()\n",
    "    fig, ax = plt.subplots()\n",
    "    y_pos = np.arange(len(cat_plot))\n",
    "    \n",
    "    hatch, color, fill = [], [], []\n",
    "    for i in per_incr:\n",
    "        if i < 0:\n",
    "            hatch.append('xxx')\n",
    "            color.append('b')\n",
    "            fill.append(False)\n",
    "        else:\n",
    "            hatch.append('xxx')\n",
    "            color.append('b')\n",
    "            fill.append(True)\n",
    "\n",
    "    print(len(y_pos), len(per_incr))        \n",
    "    barlist = ax.barh(y_pos, per_incr, align='center',xerr=std_err)\n",
    "    for i,thisbar in enumerate(barlist.patches):\n",
    "        thisbar.set_hatch(hatch[i])\n",
    "        thisbar.set_color(color[i])\n",
    "        thisbar.set_fill(fill[i])\n",
    "    \n",
    "    majorLocator = MultipleLocator(20)\n",
    "    majorFormatter = FormatStrFormatter('%d')\n",
    "    minorLocator = MultipleLocator(2.5)\n",
    "\n",
    "    ax.xaxis.set_major_locator(majorLocator)\n",
    "    ax.xaxis.set_major_formatter(majorFormatter)\n",
    "\n",
    "    # for the minor ticks, use no labels; default NullFormatter\n",
    "    ax.xaxis.set_minor_locator(minorLocator)\n",
    "\n",
    "    ax.set_yticks(y_pos)\n",
    "    plt.ylim(-1,16)\n",
    "    ax.set_yticklabels(cat_plot)\n",
    "    ax.invert_yaxis()  # labels read top-to-bottom\n",
    "    ax.set_xlabel('Advantage (%)')\n",
    "    plt.xlim(-50,50)\n",
    "    #plt.xlim(-70,70)\n",
    "    #x_pos = np.arange(-45,60,step=15)\n",
    "    x_pos = np.arange(-50, 60, step=10)\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels([50, 40, 30, 20, 10, 0, 10, 20, 30, 40, 50])\n",
    "    #ax.set_xticklabels([45,30,15,0,15,30,45])\n",
    "    plt.axvline(0, color='black')\n",
    "    plt.axhline(14.58, color='black')\n",
    "    plt.text(-40, 0, grp_1, fontsize=23)\n",
    "    plt.text(35, 0, grp_2, fontsize=23)\n",
    "    plt.grid(linestyle='--')\n",
    "    ax.get_yticklabels()[-1].set_color(\"m\")\n",
    "    title = grp_1 + '_' + grp_2 + '.jpg'\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(dir_ + '/' + title, dpi=250)\n",
    "    #plt.savefig('plotNatural/'+title, format='svg', dpi=1200)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrap sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# categories = ['Books','Electronics','CDs & Vinyl','Clothing, Shoes & Jewelry','Home & Kitchen',\\\n",
    "#              'Kindle Store','Sports & Outdoors','Cell Phones & Accessories', 'Toys & Games','Games','Literature & Fiction',\\\n",
    "#              'Beauty','Health & Personal Care','Movies','Computers']\n",
    "\n",
    "all_res = []\n",
    "sample_times = 1\n",
    "for i in range(0, sample_times):\n",
    "    all_results = {}\n",
    "    for category in categories:\n",
    "        bootstrap_res = {}\n",
    "        path = 'category_pairs/sample_' + str(i) + '/' + category + '.pickle'\n",
    "        with open(path, 'rb') as fs:\n",
    "            pairs = pickle.load(fs)\n",
    "        res, _ = calculateMetric(pairs, bootstrap=True)\n",
    "        # scipy.stats.sem\n",
    "        all_results[category] = res\n",
    "\n",
    "        print(f'done for {category}')\n",
    "    \n",
    "    print(f'sample {i} finished')\n",
    "    all_res.append(all_results) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResults(res, key):\n",
    "    val = []\n",
    "    std_err = []\n",
    "    for category in categories:\n",
    "        val.append(res[category][key][0])\n",
    "        std_err.append(res[category][key][1])\n",
    "\n",
    "    mean = np.mean(val)\n",
    "    val.append(mean)\n",
    "    std_err.append(0)\n",
    "    return val, std_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '0-1', '0-2', '2-3', '1-3'\n",
    "# DISCLOSED_MALE = 0\n",
    "# DISCLOSED_FEMALE = 1\n",
    "# UNDISCLOSED_MALE = 2\n",
    "# UNDISCLOSED_FEMALE = 3\n",
    "val, std_err = getResults(all_res[0], '0-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PM: Performative Male (undisclosed), SM: Singnal Male (disclosed)\n",
    "plotResults(val, 'PM', 'SM', std_err=std_err, dir_='./')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [deprecated] Calculate covariate distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['Books','Electronics','CDs & Vinyl','Clothing, Shoes & Jewelry','Home & Kitchen',\\\n",
    "             'Kindle Store','Sports & Outdoors','Cell Phones & Accessories', 'Toys & Games','Games','Literature & Fiction',\\\n",
    "             'Beauty','Health & Personal Care','Movies','Computers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = 'Books'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'category_pairs/sample_3/' + category + '.pickle'\n",
    "with open(path,'rb') as fs:\n",
    "    pairs = pickle.load(fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs['1-0'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDistribution(lst):\n",
    "    u_el = list(set(lst))\n",
    "    u_el.sort()\n",
    "    dist = []\n",
    "    for el in u_el:\n",
    "        el_cnt = lst.count(el)\n",
    "        dist.append(el_cnt)\n",
    "    s = sum(dist)\n",
    "    return u_el, [i/s for i in dist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcCovariateHist(pairs,x_label=None,covariate=None):\n",
    "    keys = ['0-1', '1-0', '2-3', '3-2', '1-3', '3-1', '0-2', '2-0']\n",
    "    \n",
    "    confounder = {}\n",
    "    \n",
    "    for key in keys:\n",
    "        for pair in pairs[key]:\n",
    "            x = pair[0]['group']\n",
    "            val_x = pair[0][covariate]\n",
    "            y = pair[1]['group']\n",
    "            val_y = pair[1][covariate]\n",
    "            if x not in confounder:\n",
    "                confounder[x] = []\n",
    "            if y not in confounder:\n",
    "                confounder[y] = []\n",
    "            confounder[x].append(val_x)\n",
    "            confounder[y].append(val_y)\n",
    "    \n",
    "    \n",
    "    confounder_fil = {}\n",
    "    confounder_fil[0] = [i for i in confounder[0] if i in range(1,16)]\n",
    "    confounder_fil[1] = [i for i in confounder[1] if i in range(1,16)]\n",
    "    confounder_fil[2] = [i for i in confounder[2] if i in range(1,16)]\n",
    "    confounder_fil[3] = [i for i in confounder[3] if i in range(1,16)]\n",
    "    \n",
    "    print(min(confounder_fil[0]),max(confounder_fil[0]))\n",
    "    print(min(confounder_fil[1]),max(confounder_fil[1]))\n",
    "    print(min(confounder_fil[2]),max(confounder_fil[2]))\n",
    "    print(min(confounder_fil[3]),max(confounder_fil[3]))\n",
    "    \n",
    "    width = 0.15\n",
    "    fig, ax = plt.subplots()\n",
    "    colors = ['b','r','b','r']\n",
    "    edge_colors = [None,None,'b','r']\n",
    "    #hatches = ['','','xxx','xxx']\n",
    "    linestyles = ['-','-','--','--']\n",
    "    fills = [True,True,False,False]\n",
    "    labels = ['SM','SW','PM','PW']\n",
    "    #x_pos = np.arange(1.5,60,step=10)\n",
    "    #ax.set_xticks(x_pos)\n",
    "    #ax.set_xticklabels([50,40,30,20,10,0,10,20,30,40,50])\n",
    "    #print(min(confounder[0]),min(confounder[1]),min(confounder[2]),min(confounder[3]))\n",
    "    for i in range(4):\n",
    "        x,dist = createDistribution(confounder_fil[i])\n",
    "        plt.plot(x,dist,color = colors[i],label = labels[i],linewidth=2,linestyle = linestyles[i])\n",
    "        #x = [i*width+j for j in x]\n",
    "        #plt.bar(x,dist,color=colors[i],hatch=hatches[i],fill=fills[i],label=labels[i],width=0.15,edgecolor=edge_colors[i])\n",
    "    \n",
    "    index = np.arange(1,16)\n",
    "    plt.xticks(index + width*1.5, (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15))\n",
    "    plt.grid(linestyle='--')\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel('PMF')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plotCovariates/'+covariate+'.jpg',dpi=250)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = calcCovariateHist(pairs,x_label='Readability',covariate='Grade_level')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcCovariateDist(pairs,t,x_label='Readability',covariate='Grade_level'):\n",
    "    \n",
    "    flag = 0\n",
    "    dists_all = []\n",
    "    for i in range(4):\n",
    "        if i!=t:\n",
    "            if flag==0:\n",
    "                grp_0_1 = [(m[covariate],n[covariate]) for m,n in pairs[str(t)+'-'+str(i)]]\n",
    "                #grp_1_0 = [(n[covariate],m[covariate]) for m,n in pairs[str(i)+'-'+str(t)]]\n",
    "                #grp = grp_0_1 + grp_1_0\n",
    "                dist = list(zip(*grp_0_1))\n",
    "            \n",
    "                dist_0 = list(dist[0])\n",
    "                dists_all.append(list(dist[1]))\n",
    "            \n",
    "            else:\n",
    "                dists_all.append([n[covariate] for m,n in pairs[str(t)+'-'+str(i)]])\n",
    "                \n",
    "            #val,p = ks_2samp(dist_0,dist_1)\n",
    "            #print(val,p)\n",
    "            #dist_0.sort()\n",
    "            #dist_1.sort()\n",
    "            #y_1 = np.cumsum(dist_0)\n",
    "            #y_2 = np.cumsum(dist_1)\n",
    "            \n",
    "    #y,binEdges=np.histogram(dist_0,bins=100)\n",
    "    #bincenters = 0.5*(binEdges[1:]+binEdges[:-1])\n",
    "    #plt.plot(bincenters,y,'-',linewidth=2)\n",
    "    sns.distplot(dist_0,hist=False,rug=True,label='DM',kde_kws={'color':'b','linewidth':2})\n",
    "    \n",
    "    colors = ['r','b','r']\n",
    "    ls = ['-','--','--']\n",
    "    labels = ['DW','UM','UW']\n",
    "    \n",
    "    for i,dist in enumerate(dists_all):\n",
    "\n",
    "        #y,binEdges=np.histogram(dist,bins=100)\n",
    "        #bincenters = 0.5*(binEdges[1:]+binEdges[:-1])\n",
    "        #plt.plot(bincenters,y,'-',linewidth=2)\n",
    "        sns.distplot(dist,hist=False,rug=True,label=labels[i],\n",
    "                     kde_kws={'color':colors[i],'linestyle':ls[i],'linewidth':2})\n",
    "\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel('PDF')\n",
    "    plt.grid(linestyle='--')\n",
    "    #plt.xscale('log')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('plotCovariates/'+covariate+'.jpg',dpi=250)\n",
    "    \n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs['0-1'][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calcCovariateDist(pairs,0,x_label='Rating',covariate='Rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kruskal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_m_s = dis_male.sample(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_m_s = undis_male.sample(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_f_s = dis_female.sample(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_f_s = undis_female.sample(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kruskal(d_m_s['overall_sentiment'],u_m_s['overall_sentiment'],d_f_s['overall_sentiment'],u_f_s['overall_sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import MultipleLocator, FormatStrFormatter\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "#mpl.style.use('classic')\n",
    "mpl.rcParams['xtick.labelsize'] = 25\n",
    "mpl.rcParams['ytick.labelsize'] = 32\n",
    "mpl.rcParams['font.size'] = 20\n",
    "mpl.rcParams['figure.figsize'] =  9,10\n",
    "mpl.rcParams['axes.labelsize'] = 35\n",
    "mpl.rcParams['mathtext.fontset'] = 'stix'\n",
    "mpl.rcParams['font.family'] = 'STIXGeneral'\n",
    "mpl.rcParams['axes.linewidth'] = 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calcCovariateDist(pairs,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
