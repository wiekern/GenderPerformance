{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yelp (csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [optional] only run if **train_data_full.csv** not exists\n",
    "# Merging seperated csv data into one Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "data_dir = Path.cwd() / 'datasets/yelp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = Path.home() / 'GenderPerformance/datasets/yelp'\n",
    "# 0: business, 1: checkin, 2: photo, 3: review, 4: tip, 5: user\n",
    "# data_class = {'business': 'business', 'checkin': 'checkin', 'photo': 'photo', 'review': 'review', 'tip': 'tip', 'user': 'user'}\n",
    "\n",
    "business_df = pd.read_csv(data_dir / 'business.csv', usecols=['business_id', 'name', 'categories'])\n",
    "review_df = pd.read_csv(data_dir / 'review.csv', usecols=['review_id', 'user_id', 'business_id', 'stars', 'date', 'useful', 'text'])\n",
    "user_df = pd.read_csv(data_dir / 'user.csv', usecols=['user_id', 'name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_business_category(business_id):\n",
    "    return business_df[business_df['business_id'] == business_id]['categories']\n",
    "\n",
    "def get_username(user_id):\n",
    "    return user_df[user_df['user_id'] == user_id]['name']\n",
    "\n",
    "def date_to_timestamp(date_str):\n",
    "    return time.mktime(datetime.datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S').timetuple())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refining interested attributes\n",
    "business_df.rename(columns={'name': 'business_name'}, inplace=True)\n",
    "business_df = business_df.dropna(axis=0)\n",
    "user_df.rename(columns={'name': 'user_name'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting  categories correlated to 'restaurants' \n",
    "coproduct for NaturalExptCategory(not_pairwise), not used here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_dir = Path.home() / 'GenderPerformance/datasets/yelp'\n",
    "\n",
    "business_df = pd.read_csv(data_dir + 'business.csv', usecols=['business_id', 'name', 'categories'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_df['categories_lower'] = business_df['categories'].apply(lambda x: str(x).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories = business_df['categories_lower'].unique()\n",
    "categories = business_df['categories_lower']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directly correlated to 'restaurants'\n",
    "split_cates = [None] * len(categories)\n",
    "correlated_categories = {}\n",
    "for c_k, c_v in enumerate(categories):\n",
    "    if 'restaurants' in c_v:\n",
    "        split_cates[c_k] = c_v.lower().split(',')\n",
    "        for c in split_cates[c_k]:\n",
    "            c_striped = c.strip()\n",
    "            correlated_categories[c_striped] = correlated_categories.get(c_striped, 0) + 1\n",
    " \n",
    "with open(data_dir / 'directly_correlated_categories.json', 'w') as f:\n",
    "    json.dump(correlated_categories, f)\n",
    "\n",
    "sorted_correlated_categories = sorted(correlated_categories.items(), key=lambda kv: kv[1], reverse=True)\n",
    "print(sorted_correlated_categories[:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlated_categories = {'restaurants': False, 'chinese': False}\n",
    "import queue\n",
    "q = queue.Queue()\n",
    "for key in correlated_categories:\n",
    "    q.put(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('# of directly correlated: ', len(correlated_categories))\n",
    "\n",
    "def bfs_category():\n",
    "    while not q.empty():\n",
    "        element = q.get()\n",
    "        if element is None:\n",
    "            break;\n",
    "\n",
    "#         print('element:', element)\n",
    "        for c in categories:\n",
    "            if element in c:\n",
    "                split_categories = c.lower().split(',')\n",
    "                for split_categoy in split_categories:\n",
    "                    split_categoy = split_categoy.strip()\n",
    "                    correlated_categories[split_categoy] = correlated_categories.get(split_categoy, 0) + 1\n",
    "                    if split_categoy not in correlated_categories:\n",
    "#                         print('new:', split_categoy)\n",
    "                        q.put(split_categoy)\n",
    "bfs_category()\n",
    "print('# of directly and undirectly correlated: ', len(correlated_categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(correlated_categories)\n",
    "sorted_cates = sorted(correlated_categories.items(), key=lambda kv: kv[1], reverse=True)\n",
    "print(sorted_cates[:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(correlated_categories)\n",
    "import json\n",
    "with open(data_dir / 'all_correlated_categories.json', 'w') as f:\n",
    "    json.dump(correlated_categories, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting top N unique independent categories\n",
    "coproduct for NaturalExptCategory(not_pairwise), not used here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_df = business_df.dropna(axis=0)\n",
    "categories_column =  business_df.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_freq = {}\n",
    "for cate in categories_column:\n",
    "    for sub_cate in cate.lower().split(','):\n",
    "        sub_cate = sub_cate.strip()\n",
    "        category_freq[sub_cate] = category_freq.get(sub_cate, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_category_freq = sorted(category_freq.items(), key=lambda kv: kv[1], reverse=True)\n",
    "with open(data_dir / 'top_10_categories.json', 'w') as f:\n",
    "    json.dump(sorted_category_freq[:10], f)\n",
    "len(sorted_category_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_category_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "directly = True\n",
    "if directly:\n",
    "    with open(data_dir / 'directly_correlated_categories.json') as json_file:\n",
    "        restaurants_related_categories = json.load(json_file)\n",
    "else:\n",
    "    with open(data_dir / 'all_correlated_categories.json', 'w') as json_file:\n",
    "        restaurants_related_categories = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interest_categories = {}\n",
    "top_n = 5\n",
    "for category_tuple in sorted_category_freq:\n",
    "    if len(interest_categories) >= top_n:\n",
    "        break\n",
    "    \n",
    "#     print(category_tuple[0], correlated_categories[category_tuple[0]])\n",
    "    if category_tuple[0] not in restaurants_related_categories:\n",
    "        interest_categories[category_tuple[0]] = category_tuple[1]\n",
    "\n",
    "\n",
    "interest_categories['restaurants'] = correlated_categories['restaurants']\n",
    "print('interested categories:', interest_categories)\n",
    "print(sorted_category_freq[:10])\n",
    "import json\n",
    "with open(data_dir / 'top_n_correlated_categories.json', 'w') as f:\n",
    "    json.dump(interest_categories, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(review_df, business_df, on='business_id', how='outer')\n",
    "merged_df = pd.merge(merged_df, user_df, on='user_id', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged_df = merged_df.dropna(axis=0) # drop rows where NAN exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['timestamp'] = merged_df['date'].apply(lambda x:date_to_timestamp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['text'].replace(to_replace=[r\"\\\\t|\\\\n|\\\\r\", \"\\t|\\n|\\r\"], value=[\"\",\"\"], regex=True, inplace=True)\n",
    "merged_df.to_csv(data_dir / 'train_data_full.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.read_csv(data_dir / 'train_data_full.csv')\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path.home() / 'GenderPerformance/datasets/yelp'\n",
    "business_df = pd.read_csv(data_dir + 'business.csv', usecols=['business_id', 'categories'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(merged_df, business_df, on='business_id', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('train_data_full_cate.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading complete data from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import pandas as pd\n",
    "if not os.path.exists(data_dir / 'train_data_full.csv'):\n",
    "    merged_df.to_csv('train_data_full.csv', index=False)\n",
    "\n",
    "if merged_df is None:\n",
    "    merged_df = pd.read_csv(data_dir / 'train_data_full.csv')\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gender_guesser.detector as gender\n",
    "\n",
    "d = gender.Detector(case_sensitive=False)\n",
    "\n",
    "import string\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "def get_gender(name):\n",
    "    try:\n",
    "        n = name.lower()\n",
    "        if ('mom' in n) or ('girl' in n) or ('angel' in n) or ('mum' in n) or ('mother' in n) or ('woman' in n):\n",
    "            return 'female'\n",
    "        if ('boy' in n) or ('dude' in n):\n",
    "            return 'male'\n",
    "        temp = name.translate(translator).split()\n",
    "    except:\n",
    "        return 'unknown'\n",
    "    \n",
    "    if len(temp) > 0:\n",
    "        first_name = temp[0]\n",
    "        first_name = ''.join([i for i in first_name if not i.isdigit()])\n",
    "        gender = d.get_gender(first_name,'usa')\n",
    "        return gender\n",
    "    else:\n",
    "        return 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_gender())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['gender'] = merged_df['user_name'].apply(lambda x:get_gender(x))\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disclosed_flags = merged_df['gender'].isin(['female', 'male'])\n",
    "undisclosed_flags = ~disclosed_flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disclosed_gender_df = merged_df[disclosed_flags]\n",
    "disclosed_gender_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disclosed_gender_df = disclosed_gender_df.drop(columns=['gender'])\n",
    "disclosed_gender_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "undisclosed_gender_df = merged_df[undisclosed_flags]\n",
    "undisclosed_gender_df = undisclosed_gender_df.drop(columns=['Gender'])\n",
    "undisclosed_gender_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save disclosed and undisclosed whole data to csv, if csv file exists, reading them in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import pandas as pd\n",
    "if not os.path.exists(data_dir / 'disclosed_dataset.csv'):\n",
    "    print('saving disclosed dataset to csv')\n",
    "    disclosed_gender_df.to_csv(data_dir / 'disclosed_dataset.csv', index=False)\n",
    "else:\n",
    "    disclosed_gender_df = pd.read_csv(data_dir / 'disclosed_dataset.csv')\n",
    "\n",
    "if not os.path.exists(data_dir / 'undisclosed_dataset.csv'):\n",
    "    print('saving undisclosed dataset to csv')\n",
    "    undisclosed_gender_df.to_csv(data_dir / 'undisclosed_dataset.csv', index=False)\n",
    "else:\n",
    "    undisclosed_gender_df = pd.read_csv(data_dir / 'undisclosed_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "undisclosed_gender_df = undisclosed_gender_df[['user_id', 'text', 'gender']]\n",
    "# undisclosed_gender_df.replace(to_replace=[r\"\\\\t|\\\\n|\\\\r\", \"\\t|\\n|\\r\"], value=[\"\",\"\"], regex=True, inplace=True)\n",
    "undisclosed_gender_df.to_csv(data_dir / 'undisclosed_id_text_gender.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'female' : 1, 'male' : 0}\n",
    "disclosed_dataset_df = disclosed_gender_df[['user_name', 'text', 'gender']]\n",
    "disclosed_dataset_df.replace({'gender': mapping}, inplace=True)\n",
    "disclosed_dataset_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_shape = disclosed_dataset_df.loc[disclosed_dataset_df['gender'] == 1].shape\n",
    "DM_shape = disclosed_dataset_df.loc[disclosed_dataset_df['gender'] == 0].shape\n",
    "UNDIS_shape = undisclosed_gender_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_size = disclosed_dataset_df.shape[0] + UNDIS_shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(total_size, disclosed_dataset_df.shape[0], UNDIS_shape[0], DM_shape[0], DF_shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "labels = 'SM', 'SW', 'Performing'\n",
    "sizes = [DM_shape[0]/total_size, DF_shape[0]/total_size, UNDIS_shape[0]/total_size]\n",
    "explode = (0, 0, 0)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split disclosed dataset into train, test and validation\n",
    "# train: text, gender\n",
    "# test: name, text, gender\n",
    "# validation: text, gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# dataset_df = pd.read_csv('train_dataset.csv')\n",
    "if 'disclosed_dataset_df' in locals():\n",
    "    # 80/20 train/test\n",
    "    train_df, test_df = train_test_split(disclosed_dataset_df, test_size=0.2)\n",
    "    # 80/20 train/validation\n",
    "    train_df, validation_df = train_test_split(train_df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting related attributes for training, validation and test\n",
    "train_gender_text_df = train_df[['gender', 'text']]\n",
    "validation_gender_text_df = validation_df[['gender', 'text']]\n",
    "test_name_text_gender_df = test_df[['user_name', 'text', 'gender']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2_test_df = pd.read_csv('v2_test_data.csv', engine='python',  encoding='utf-8', error_bad_lines=False, header=None)\n",
    "# train_gender_text_df.replace(to_replace=[r\"\\\\t|\\\\n|\\\\r\", \"\\t|\\n|\\r\"], value=[\"\",\"\"], regex=True, inplace=True)\n",
    "train_gender_text_df.to_csv(data_dir / 'training_gender_text.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation_gender_text_df.replace(to_replace=[r\"\\\\t|\\\\n|\\\\r\", \"\\t|\\n|\\r\"], value=[\"\",\"\"], regex=True, inplace=True)\n",
    "validation_gender_text_df.to_csv(data_dir / 'validation_gender_text.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_name_text_gender_df.replace(to_replace=[r\"\\\\t|\\\\n|\\\\r\", \"\\t|\\n|\\r\"], value=[\"\",\"\"], regex=True, inplace=True)\n",
    "test_name_text_gender_df.to_csv(data_dir / 'test_name_text_gender.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper function removing escape chars and checking if successfully removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Legacy\n",
    "def remove_(x):\n",
    "    x = str(x).replace('\\n', ' ')\n",
    "    return x\n",
    "\n",
    "v1_test_df['Review'] = v1_test_df[1].apply(lambda x:remove_(x))\n",
    "\n",
    "def check(x):\n",
    "    if '\\n' in x:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "v1_test_df['check'] = v1_test_df['Review'].apply(lambda x:check(x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
